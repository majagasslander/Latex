\documentclass{article}
\usepackage[utf8x]{inputenc}
\usepackage{fontenc}
\usepackage{hyperref}
\usepackage[square,numbers]{natbib}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[margin=1.4in]{geometry}
\usepackage{amssymb, graphics, setspace, mathtools}
\usepackage{multirow}
\bibliographystyle{abbrvnat}


\title{Master Thesis Outline TQET33 \\
\normalsize{The Institute of Technology at Linköping University}}


\author{Maja Gasslander \\ \normalsize{maja.gasslander@gmail.com}}

%\date{November 16, 2015}

\begin{document}
\maketitle
\newpage
\section{Introduction}
This master thesis will be carried out at Vricon. Supervisor at Vricon is Anton Nordmark, supervisor at ISY is Martin Danelljan and the examiner is Fahad Khan at ISY. 

\subsection{Contact Information}
Anton Nordmark: \href{mailto:anton.nordmark@vricon.com}{anton.nordmark@vricon.com}\\
Martin Danelljan: \href{mailto:martin.danelljan@liu.se}{martin.danelljan@liu.se} \\
Fahad Khan: \href{mailto:fahad.khan@liu.se}{fahad.khan@liu.se}


\section{Preliminary Title}
A preliminary title for the master thesis is \emph{Segmentation of Clouds in Satellite Images.} 

\section{Problem Formulation}
The aim of this thesis is to segment satellite images into cloud and non-cloud pixels. Different combinations of existing methods for feature extraction and classification will be evaluated. The goal is to investigate machine learning based approaches for segmenting the pixels.

\section{Approach}
A preliminary approach for solving the task is divided into several subproblems. Each subproblem is described in more detail in the subsections below. The proposed pipeline can be seen in figure \ref{fig:pipeline}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{fig/pipeline}
    \caption{Pipeline}
    \label{fig:pipeline}
\end{figure}

\subsection{Data}
All images used for cloud classification will be provided by Vricon. Each image contains both panchromatic, i.e. black and white, high resolution data, and also an eight band multispectral imagery. From these images the training data are created and represented as a feature vector, each with an assigned class label. Images with various types of landscape and cloud amount will be used for the classification.

\subsection{Preparatory work}
Before it is possible to start working on the actual problem, some minor administration has to be done. For example creating a working directory and a user in Vricons system. Also, since a lot of their own functions will be used for handling the images, some small amount of time will be used to understand their code.

\subsection{Pre processing}
To make the classification easier the images are pre processed. This will be done by tiling the images into smaller tiles. If necessary, a histogram equalization will be applied. This will flatten the greylevel histogram of the image so that all intensities are as equal as possible and thereby the image contrast is increased.
%An alternative to tiling is to do a superpixel segmentation that will be taken into consideration.
%\subsubsection{Tiling}
%First the image $I$ is divided into smaller tiles, $I_k$. To avoid wrong classification in the tiles containing cloud boundaries, overlapping tiles is used. 

%\subsubsection{Edge detection}
%Since clouds contains very little sharp edges, many of the non-cloud tiles can be sorted away by calculating the edges with the canny edge detector \citep{canny}.

%\subsubsection{Histogram Equalization}

\subsection{Feature Extraction}
After the pre processing is done it is time to perform the feature extraction. A good feature clearly seperates the two classes from each other. Texture and color are the two features that will recieve the biggest focus in this master thesis. 
\subsubsection{Texture}

\begin{itemize}
\item Gabor Filters: \\
A set of Gabor filters with different frequencies and orientation might be good to extract texture features from the clouds  \citep{gabor}.
The equation for a complex Gabor filter looks like follows:
\begin{equation}
g(x, y; \lambda, \theta, \psi, \sigma, \gamma) = e^{-\frac{x'^2 + \gamma^2y'^2}{2\sigma^2}}e^{i(2\pi\frac{x'}{\lambda} + \psi)}
\end{equation}
where \\
$x' = x\cos\theta + y\sin\theta$ \\
and \\
$y' = -x\sin\theta + y\cos\theta$

\item Homogeneous Texture Descriptor: \\
Clouds have a very homogeneous texture, so the Homogeneous Texture Descriptor (HTD) might be good to extract texture features in the clouds. It is based on computing the local spatial-frequency statistics of the texture, \citep{htd}.

\item Grey level co-occurrence matrix: \\
A grey level co-occurrence matrix (GLCM) is a histogram of co-occurring greyscale values at a given offset over an image. The GLCM functions characterize the texture of an image by calculating how often pairs of pixels with specific values and in a specified spatial relationship occur in an image.

\item Local Binary Pattern \citep{LBP}: \\ 
In Local Binary Pattern (LBP), each pixel in an image tile is compared to its 8 neighbouring pixels. For each tile a histogram is computed.
\item Histogram of Oriented Gradients \citep{hog}: \\
The Histogram of Oriented Gradients (HOG) is a feature descriptor that counts the occurences of gradient orientation in a local area of an image.
\end{itemize}
\subsubsection{Color}
Since the clouds often differ in color compared to other areas with similar texture (for example water), color might be a good feature for the classification. Two methods for color extraction that will be tested is RGB histogram, and Color Names. Color Naming is the action of assigning linguistic color labels to image pixels \citep{colornames}.


\subsection{Classification}
For the classification Support Vector Machines (SVM) will be uesd. SVM is a supervised learning method. 
Consider a set of \textit{training} vectors $ \textbf{x}_{i}, i = 1,...,k $, which are the feature vectors, and the corresponding vector $ \textbf{y} $ of length $ k $ containing the class values; 

\begin{equation}
y_{i} =
\begin{cases}
1, & \text{if $\textbf{x}_{i}$ in class 1} \\
-1,
& \text{if $\textbf{x}_{i}$ in class 2}
\end{cases}
\end{equation}
Then we have the separating hyperplane as $\textbf{w}^{T}\textbf{x} + b = 0$

\begin{equation}
\label{eq:hyp}
\begin{cases}
(\textbf{w}^{T}\textbf{x}_{i}) + b > 0 & \text{if $y_{i} = 1$} \\
(\textbf{w}^{T}\textbf{x}_{i}) + b < 0 & \text{if $y_{i} = -1$}
\end{cases}
\end{equation}

The decision function then becomes $f(\textbf{x}) = sgn(\textbf{w}^{T}\textbf{x} + b)$, where $ \textbf{x} $ is the testdata. There are many possible choices for $\textbf{w}$ and $b$.
Equation \ref{eq:hyp} can be rewritten as 

\begin{equation}
y_{i}(\textbf{w}^{T}\textbf{x}_{i} + b) \geq 1, \text{for all $1 \leq i \leq k$}
\end{equation}

which gives an optimization problem: 

\begin{equation}
\min_{\textbf{w},b} \dfrac{1}{2}\textbf{w}^{T}\textbf{w}
\end{equation}

subject to (for all $ i = 1,...,k $)

\begin{equation*}
y_{i}(\textbf{w}^{T}\textbf{x}_{i} + b) \geq 1
\end{equation*}

If the data is not linearly seperable it can be mapped to a higher dimensional feature space using the Kernel trick: $ K(\textbf{x}_{i},\textbf{x}_{j}) = \phi(\textbf{x}_{i})^{T}\phi(\textbf{x}_{j}) $ \\
where
\begin{equation*}
\phi(\textbf{x}_{i}) = (\phi_{1}(\textbf{x}_{i}), \phi_{2}(\textbf{x}_{i}),...)
\end{equation*}
Also a slack variable is introduced to allow mislabeled examples. The optimization becomes a trade off between a large margin and a small error penalty. The new equation is:

\begin{equation}
\min_{\textbf{w},b, \xi} \dfrac{1}{2}\textbf{w}^{T}\textbf{w} + C\sum_{1 = 1}^{k}\xi_{i}
\end{equation}
\begin{equation*}
\xi_{i} \geq 0, i = 1,...,k
\end{equation*}
subject to (for all $ i = 1,...,k $)

\begin{equation*}
y_{i}(\textbf{w}^{T}\phi(\textbf{x}_{i}) + b) \geq 1 - \xi_{i}
\end{equation*}

Some common kernels that will be tested during this thesis are:
\begin{itemize}
\item Linear Kernel: $K(\textbf{x}_i,\textbf{x}_{j}) = \textbf{x}_i\cdot\textbf{x}_{j}$

\item Polynomial Kernel: $K(\textbf{x}_i,\textbf{x}_{j}) = (\gamma\textbf{x}_i\cdot\textbf{x}_{j} + r)^d, \gamma > 0$

\item Gaussian Radial Basis Function: $K(\textbf{x}_i,\textbf{x}_{j}) = e^{(-\gamma\|\textbf{x}_i-\textbf{x}_{j}\|)^2}, \gamma > 0$

\item Sigmoid Kernel: $K(\textbf{x}_i,\textbf{x}_{j}) = \tanh(\gamma\textbf{x}_i\cdot\textbf{x}_{j} + r)$
\end{itemize}

\subsection{Postprocessing}

After the classification is done some postprocessing might need to be implemented to clean up some of the wrongly classified objects. Markov Random Fields (MRFs) is an effective classification postprocessing strategy, that smoothes the classification and provides more homogenous results \citep{mrf}. The MRF model can be written 
\begin{equation*}
E(X,C) = -\sum_{x\in X}\ln(p_{x,i}) + \beta\sum_{y\in N_{x}}[1 - \delta(C(x), C(y)]
\end{equation*}
where $X$ and $C$ denotes the image and its labeling space, $N_{x}$ represents the neighbourhood centered by pixel $x$. $C(x)$ and $C(y)$ are the labels of pixel x and y. $\delta(x,y)$ is the Kronecker function, i.e. $\delta(x,y) = a$ for $x = y$ and $\delta(x,y) = 0$ for $x \neq y$, used to penalize the change of labels in the neighbourhood $N_{x}$.

\subsection{Evaluation}
When the classification is done the result needs to be evaluated to know how the algorithm performed. This will be done by comparing the classified images to a hand labeled ground truth. Some ground truth already exists, and some might need to be hand labeled during the thesis. 
Two measures for evaluation will be used:
\begin{itemize}
\item Confusion Matrix: \\
A Confusion Matrix is a matrix containing the counts of correctly and incorrectly labeled data, see table \ref{confmat}.

\begin{table}[h!]
	\centering
	\begin{tabular}{cccc}
		& \multicolumn{3}{c}{\textbf{Predicted Class}} \\ \cline{2-4} 
		\multicolumn{1}{c|}{\multirow{6}{*}{\textbf{\rotatebox[origin=c]{90}{Actual Class}}}} & \multicolumn{1}{c|}{\multirow{2}{*}{}} & \multicolumn{1}{c|}{\multirow{2}{*}{Class 1}} & \multicolumn{1}{c|}{\multirow{2}{*}{Class 2}} \\
		\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} \\ \cline{2-4} 
		\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{\multirow{2}{*}{Class 1}} & \multicolumn{1}{c|}{\multirow{2}{*}{$f_{11}$}} & \multicolumn{1}{c|}{\multirow{2}{*}{$f_{12}$}} \\
		\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} \\ \cline{2-4} 
		\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{\multirow{2}{*}{Class 2}} & \multicolumn{1}{c|}{\multirow{2}{*}{$f_{21}$}} & \multicolumn{1}{c|}{\multirow{2}{*}{$f_{22}$}} \\
		\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} \\ \cline{2-4} 
	\end{tabular}
	\caption{A Confusion Matrix between 2 classes}
	\label{confmat}
\end{table}
%\rotatebox[origin=c]{90}{Actual Class}



\item Receiver operating characteristic: \\
A receiver operating characteristic (ROC), or ROC curve is a graphical plot that illustrates the performance of a binary classifier. The plot is generated by plotting the true positiv rate against the false positiv rate at different threshold settings.
\end{itemize}



\section{Time Plan}
The given task has been divided into several sub tasks to easier plan the work. The estimated time for each sub task is listed in the time plan in figure \ref{fig:timeplan} below.
Note that week 53-2 and week 11-12 are marked red because of Christmas break and exams.

%\subsection{Activities}
%\begin{itemize}
%\item Literature study.
%\item Preparatory work.
%item Preprocessing
%item Feature extraction texture
%\item Feature extraction color
%\item Classification
%\item Evaluation
%\item Documentation
%\item Presentation
%\item Opposition
%\item Meetings supervisor
%\end{itemize}

\subsection{Preliminary dates}
\begin{itemize}
\item Half-time Control: February 3, 2016.
\item Presentation: April 20, 2016.
\end{itemize}

\subsection{Goals for Half-time Control}
At the half-time control, preliminary dated to February 3, the main goal is to have the major part of the theory written in the master thesis report. Some preliminary results from the first classifications hopefully will be shown aswell.

\begin{figure}[h!]
    \centering
    \includegraphics[height=9 cm, width=18 cm, angle=90]{fig/Tidplan}
    \caption{Time Plan}
    \label{fig:timeplan}
\end{figure}

\newpage

\section{Literature}
\renewcommand{\section}[2]{}%
\begin{thebibliography}{9}

\bibitem{cloudcolor} 
Emre Ba\c{s}eski and \c{C}a\v{g}lar \c{S}enaras, 
\textit{Texture and Color Based Cloud Detection.} \\
HAVELSAN A.S., 2015.
 
\bibitem{cloudtexture} 
H.K. Chethan, R. Raghavendra and G. Kumar Hemantha, 
\textit{Texture based Approach for Cloud Classification using SVM.} \\
International Conference on Advances in Recent Technologies in Communication and Computing, 2009. 
 
\bibitem{canny} 
J. Canny,
\textit{A computational Approach to Edge Detection.} \\
IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986. 
 
\bibitem{woods} 
Rafael C. Gonzales and Richard E. Woods,
\textit{Digital Image Processing.} \\
Pearson Education, Inc., 2008.
 
\bibitem{gabor} 
D. Zheng, Y. Zhao and j. Wang, 
\textit{Feature Extraction using a Gabor Filter Family.} \\
Proceedings of the 6th IASTED International Conference, Signal and Image Processing, 2004. 

%\bibitem{programming} 
%Jan Erik Solem. 
%\textit{Programming Computer Vision with Python.} \\
%Creative Commons, 2004.

\bibitem{htd} 
Y. Man Ro, M. Kim, H.K. Kang, B.S. Manjunath and J. Kim,
\textit{MPEG-7 Homogeneous Texture Descriptor.} \\
ETRI Journal, volume 23, Number 2, 2001. 

\bibitem{svm} 
A. Ben-Hur and J. Weston,
\textit{A User's Guide to Support Vector Machines.} \\
ETRI Journal, volume 23, Number 2, 2001. 

\bibitem{colornames}
J. van de Weijer, C. Schmid, J. Verbeek and D. Larlus,
\textit{Learning Color Names for Real-World Applications} \\
IEEE Transactions in Image Processing,2009.

\bibitem{LBP}
Timo Ojala, Matti Pietikäinen and Topi Mäenpää,
\textit{Multiresolution Gray-Scale and Rotation Invariant Texture Classification
	with Local Binary Patterns} \\
{IEEE} Trans. Pattern Anal. Mach. Intell., volume 24, Number 7, 2009.

\bibitem{mrf}
Xin Huang, Qikai Lu, Liangpei Zhang and Antonio Plaza,
\textit{New Postprocesssing Methods for Remote Sensing Image Classification: A Systematic Study} \\
{IEEE} Transactions on Geoscience and Remote Sensing, november 2014.

\bibitem{hog}
Navneet Dalal and Bill Triggs,
\textit{Histograms of Oriented Gradients for Human Detection} \\
International Conference on Computer Vision \& Pattern Recognition, volume 2, 2009.
\\\texttt{http://lear.inrialpes.fr/pubs/2005/DT05}
%\bibitem{knuthwebsite} 
%Knuth: Computers and Typesetting,
%\\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}
\end{thebibliography}

%\bibliography{bibfile}
\end{document}
